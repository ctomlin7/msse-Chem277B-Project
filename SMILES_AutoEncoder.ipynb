{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMILES Autoencoder \n",
    "\n",
    "Replicating SMILES autoencoder in this article:  \n",
    "https://www.nature.com/articles/s42004-023-00932-3#Sec19  \n",
    "\n",
    "Supplementary material for above paper:  \n",
    "https://static-content.springer.com/esm/art%3A10.1038%2Fs42004-023-00932-3/MediaObjects/42004_2023_932_MOESM1_ESM.pdf  \n",
    "\n",
    "Model architecure and training details from above supplementary material:   \n",
    "\n",
    "• Bidirectional GRU with an encoder-decoder architecture and  \n",
    "– number of encoder and decoder layers: 3  \n",
    "– hidden dimension for encoder and decoder: 512  \n",
    "– Dimensionality of the embedding space: 512  \n",
    "– nonlinearity: tanh  \n",
    "\n",
    "Training Hyperparameters:  \n",
    "• Batch size: 256  \n",
    "• Learning rate: 0.0001  \n",
    "\n",
    "Training - The autoencoder is trained as a translation model by translating from a randomized SMILES version of a molecule\n",
    "to its canonical version. The model is trained on 135M molecules from Pubchem and ZINC12 datasets.\n",
    "The architecture of the translation model and latent dimension of 512 is similar to the one used in Winter et al.\n",
    "In order to make the learnt representations more meaningful, we also jointly trained a regression model to predict some\n",
    "molecular properties that can be calculated using the molecular structure. The regression model uses two fully connected layers\n",
    "with dimensions 512 and 128 and ReLU non-linearity. The properties that are predicted are: logP, molar refractivity, number\n",
    "of valence electrons, number of hydrogen bond donors and acceptors, Balaban’s J value, topological polar surface area, drug\n",
    "likeliness (QED) and synthetic accessibility (SA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try mol2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY PACKAGES\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of a string in the input random 'smiles' column is: 74\n",
      "Number of SMILES sequences for input sanitized dataframe: 826\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATASETS AND PAD SMILES STRINGS TO LEN=77\n",
    "\n",
    "# load dataset\n",
    "sanitized_smiles_df = pd.read_csv('dataset/sanitized_smiles_first100k.csv')     # smiles.csv file with 100K rows\n",
    "sanitized_smiles_df.rename(columns={'SMILES': 'smiles'}, inplace=True)\n",
    "\n",
    "# filter to only include SMILES strings with C, = , (, ), O, 1, 2, N\n",
    "sanitized_smiles_df = sanitized_smiles_df[sanitized_smiles_df['smiles'].str.match('^[C=()O12N]+$', na=False)]\n",
    "\n",
    "# calculate the length of each string in the 'smiles' column\n",
    "sanitized_smiles_df['length'] = sanitized_smiles_df['smiles'].apply(len)\n",
    "\n",
    "# filter dataframes to only keep input random SMILES with length 77 or less\n",
    "sanitized_smiles_df = sanitized_smiles_df[sanitized_smiles_df['length'] <= 77]\n",
    "\n",
    "# Find the maximum length\n",
    "max_length_sanitized = sanitized_smiles_df['length'].max()\n",
    "\n",
    "# Print the maximum length\n",
    "print(f\"The maximum length of a string in the input random 'smiles' column is: {max_length_sanitized}\")\n",
    "\n",
    "print(f\"Number of SMILES sequences for input sanitized dataframe: {len(sanitized_smiles_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE RANDOM SMILES SEQUENCE BY SHUFFLING SMILES STRING AND ADD TO DATAFRAME\n",
    "def shuffle_string(smiles):\n",
    "    list_smiles = list(smiles)\n",
    "    random.shuffle(list_smiles)\n",
    "    return ''.join(list_smiles)\n",
    "\n",
    "random.seed(42)  # Set random seed for reproducibility\n",
    "\n",
    "sanitized_smiles_df['random_smiles'] = sanitized_smiles_df['smiles'].apply(shuffle_string)\n",
    "\n",
    "# pad the strings in the 'smiles' column to the desired length using \" \"\n",
    "max_length = 77\n",
    "\n",
    "sanitized_smiles_df['smiles_padded'] = sanitized_smiles_df['smiles'].apply(lambda x: x.ljust(max_length, ' '))\n",
    "sanitized_smiles_df['random_smiles_padded'] = sanitized_smiles_df['random_smiles'].apply(lambda x: x.ljust(max_length, ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 9\n",
      "Shape of input SMILES tensor: torch.Size([826, 77])\n",
      "Shape of output SMILES tensor: torch.Size([826, 77])\n",
      "Shape of sampled input SMILES tensor: torch.Size([500, 77])\n",
      "Shape of sampled output SMILES tensor: torch.Size([500, 77])\n",
      "Shape of sampled input SMILES tensor- OHE: torch.Size([500, 77, 9])\n",
      "Shape of sampled output SMILES tensor- OHE: torch.Size([500, 77, 9])\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZE SMILES STRINGS (CONVERT STRING OF CHARACTERS TO LIST OF FLOATS), CONVERT TO INPUT/OUTPUT TENSORS, SAMPLE 5 SMILES SEQUENCES\n",
    "\n",
    "# Convert SMILES strings to list of characters tokens\n",
    "sanitized_smiles_df['smiles_tokenized_lists'] = sanitized_smiles_df['smiles_padded'].apply(lambda x: list(x))\n",
    "sanitized_smiles_df['random_smiles_tokenized_lists'] = sanitized_smiles_df['random_smiles_padded'].apply(lambda x: list(x))\n",
    "\n",
    "# combines each list of SMILES characters into one list\n",
    "flattened_list_all_smiles = [item for sublist in sanitized_smiles_df['smiles_tokenized_lists'] for item in sublist]\n",
    "\n",
    "# get unique characters\n",
    "unique_characters = set(flattened_list_all_smiles)\n",
    "\n",
    "# convert back to list\n",
    "unique_characters = list(unique_characters)\n",
    "unique_characters = sorted(unique_characters)\n",
    "\n",
    "print(f\"Number of unique characters: {len(unique_characters)}\")\n",
    "\n",
    "# mapping from characters to integers\n",
    "char_to_int = {char: i for i, char in enumerate(unique_characters)}\n",
    "\n",
    "# convert SMILES tokenized lists into integer lists\n",
    "random_smiles_int_lists = [\n",
    "    [char_to_int[char] for char in sublist]\n",
    "    for sublist in sanitized_smiles_df['random_smiles_tokenized_lists']\n",
    "]\n",
    "smiles_int_lists = [\n",
    "    [char_to_int[char] for char in sublist]\n",
    "    for sublist in sanitized_smiles_df['smiles_tokenized_lists']\n",
    "]\n",
    "\n",
    "sanitized_smiles_df['random_smiles_integer_lists'] = random_smiles_int_lists\n",
    "sanitized_smiles_df['smiles_integer_lists'] = smiles_int_lists\n",
    "\n",
    "# convert the tokenized sequences to tensors\n",
    "int_lists_random_smiles = sanitized_smiles_df['random_smiles_integer_lists'].tolist()\n",
    "int_lists_smiles = sanitized_smiles_df['smiles_integer_lists'].tolist()\n",
    "\n",
    "in_random_smiles_tensor = torch.tensor(int_lists_random_smiles, dtype=torch.long)\n",
    "out_smiles_tensor = torch.tensor(int_lists_smiles, dtype=torch.long)\n",
    "\n",
    "print(f\"Shape of input SMILES tensor: {in_random_smiles_tensor.shape}\")\n",
    "print(f\"Shape of output SMILES tensor: {out_smiles_tensor.shape}\")\n",
    "\n",
    "# create random sample of tensors\n",
    "\n",
    "# 500 random indices between 0 and 826\n",
    "random_indices = torch.randint(0, 826, (500,))\n",
    "\n",
    "# take the random sample of five rows from each tensor\n",
    "sample_in_smiles_tensor = in_random_smiles_tensor[random_indices]\n",
    "sample_out_smiles_tensor = out_smiles_tensor[random_indices]\n",
    "\n",
    "# Print shape of sampled rows\n",
    "print(f\"Shape of sampled input SMILES tensor: {sample_in_smiles_tensor.shape}\")\n",
    "print(f\"Shape of sampled output SMILES tensor: {sample_out_smiles_tensor.shape}\")\n",
    "\n",
    "sample_in_smiles_tensor = torch.nn.functional.one_hot(sample_in_smiles_tensor, num_classes=-1)\n",
    "sample_out_smiles_tensor = torch.nn.functional.one_hot(sample_out_smiles_tensor, num_classes=-1)\n",
    "\n",
    "print(f\"Shape of sampled input SMILES tensor- OHE: {sample_in_smiles_tensor.shape}\")\n",
    "print(f\"Shape of sampled output SMILES tensor- OHE: {sample_out_smiles_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '(': 1, ')': 2, '1': 3, '2': 4, '=': 5, 'C': 6, 'N': 7, 'O': 8}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled input SMILES tensor: tensor([[[0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 1],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sampled input SMILES tensor: {sample_in_smiles_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bidirectional_GRU_AE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=3, embedding_dim=10):\n",
    "        super(bidirectional_GRU_AE, self).__init__()\n",
    "\n",
    "        # embedding layer to convert integer indices to dense float vectors\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "\n",
    "        self.encoder = nn.GRU(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=True,\n",
    "            # input and output tensors are (batch_size, seq_len) format\n",
    "            batch_first = True      \n",
    "        )\n",
    "\n",
    "        self.decoder = nn.GRU(\n",
    "            # for bidirectional GRU, input size is doubled (each hidden layer as forward and backward state)\n",
    "            input_size=hidden_size * 2,     \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=True, \n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # fully connected layer\n",
    "        # passing through Tanh activation function (self.tanh = nn.Tanh) for nonlinearity\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, input_size),  # Linear layer\n",
    "            nn.Tanh(),  # Tanh activation\n",
    "        )\n",
    "\n",
    "    def prob_to_char_out(self, output):\n",
    "        _, predicted_classes = torch.max(output, dim=2)\n",
    "        return predicted_classes     \n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        # embed input integer indices to floating point vectors\n",
    "        # after embedding, shape of x becomes (batch size, sequence length, embedding dimensions)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # encoder_output shape is (batch size, sequence length, hidden_size * 2)\n",
    "        # hidden shape is (num_layers * 2, batch size, hidden_size)\n",
    "        encoder_output, hidden = self.encoder(x)\n",
    "        \n",
    "        # for bidirectional GRU, there are two separate hidden states for each hidden layer\n",
    "        # forward state goes from start to end of sequence and backward state goes from end to start of sequence\n",
    "        # we can concatenate forward and backward directions from last hidden layers or pass the hidden layers to the decoder directly\n",
    "        # we are currently passing hidden layers to decoder directly\n",
    "\n",
    "        # decoding\n",
    "        # encoder_output has shape (batch size, sequence length, hidden_size * 2)\n",
    "        # decoder output has shape (batch size, sequence length, hidden_size * 2)\n",
    "        decoder_output, _ = self.decoder(encoder_output, hidden)\n",
    "        print(f\"Output shape after decoder: {decoder_output.shape}\")\n",
    "\n",
    "        # pass decoder output through the fully connected layer\n",
    "        # output has shape of (batch size, sequence length, vocab size) = (5, 77, 64)\n",
    "        output = self.fc(decoder_output)\n",
    "        print(f\"Output shape after fully connected layer: {output.shape}\")\n",
    "\n",
    "        # Define custom order of classes (e.g., reversing the class order)\n",
    "        #custom_order = list(range(64))\n",
    "        #custom_order = torch.tensor(custom_order)  # This means class 3 comes first, then class 2, etc.\n",
    "\n",
    "        # Reorder the vocab_size dimension of the output tensor based on custom_order\n",
    "        #reordered_output = output[:, :, custom_order]\n",
    "\n",
    "        predicted_classes = self.prob_to_char_out(output)\n",
    "        print(f\"Predicted classes: {predicted_classes}\") \n",
    "\n",
    "        return output\n",
    "    \n",
    "int_to_char = {i: char for char, i in char_to_int.items()}\n",
    "\n",
    "def decode_smiles(tensor):\n",
    "    decoded_smiles = []\n",
    "    for sequence in tensor:\n",
    "        smiles = ''.join([int_to_char[int(idx)] for idx in sequence if int(idx) in int_to_char])\n",
    "        decoded_smiles.append(smiles.strip())  # Remove trailing spaces\n",
    "    return decoded_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 77, 9])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GRU: Expected input to be 2D or 3D, got 4D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 28\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, input_size)  \u001b[38;5;66;03m# Flatten for loss calculation\u001b[39;00m\n\u001b[1;32m     30\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten targets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/msse-python/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/msse-python/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[45], line 45\u001b[0m, in \u001b[0;36mbidirectional_GRU_AE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# encoder_output shape is (batch size, sequence length, hidden_size * 2)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# hidden shape is (num_layers * 2, batch size, hidden_size)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m encoder_output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# for bidirectional GRU, there are two separate hidden states for each hidden layer\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# forward state goes from start to end of sequence and backward state goes from end to start of sequence\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# we can concatenate forward and backward directions from last hidden layers or pass the hidden layers to the decoder directly\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# encoder_output has shape (batch size, sequence length, hidden_size * 2)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# decoder output has shape (batch size, sequence length, hidden_size * 2)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m decoder_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(encoder_output, hidden)\n",
      "File \u001b[0;32m~/miniconda3/envs/msse-python/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/msse-python/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/msse-python/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1355\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1353\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m-> 1355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRU: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1357\u001b[0m     )\n\u001b[1;32m   1358\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m   1359\u001b[0m batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: GRU: Expected input to be 2D or 3D, got 4D instead"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "seq_len = 77\n",
    "input_size = len(unique_characters)  # vocabulary size\n",
    "embed_dim = 64    \n",
    "hidden_dim = 64  \n",
    "num_layers = 3\n",
    "batch_size = 500\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# training data\n",
    "input = sample_in_smiles_tensor.long()\n",
    "#input = input.view(batch_size * num_channels, seq_len, input_size)\n",
    "target = sample_out_smiles_tensor.long()\n",
    "\n",
    "# instantiate model\n",
    "model = bidirectional_GRU_AE(input_size, hidden_dim, num_layers, embed_dim)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=char_to_int[' '])  # ignore \" \" padding indices\n",
    "\n",
    "# training loop\n",
    "losses = []\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    print(input.shape)\n",
    "    output = model(input)\n",
    "    output = output.contiguous().view(-1, input_size)  # Flatten for loss calculation\n",
    "    target = target.contiguous().view(-1)  # Flatten targets\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Decode and print the predicted SMILES\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_indices = torch.argmax(output.view(batch_size, seq_len, input_size), dim=2)\n",
    "        predicted_smiles = decode_smiles(predicted_indices)\n",
    "        random_smiles = decode_smiles(input)\n",
    "        actual_smiles = sanitized_smiles_df['smiles'].iloc[random_indices]\n",
    "        print(\"Actual vs Predicted SMILES:\")\n",
    "        for actual, random, predicted in zip(actual_smiles, random_smiles, predicted_smiles):\n",
    "            print(f\"Actual: {actual}\")\n",
    "            print(f\"Random input: {random}\")\n",
    "            print(f\"Predicted: {predicted}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "print(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msse-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
